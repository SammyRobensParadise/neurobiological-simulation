{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYDE 556/750 --- Assignment 1\n",
    "\n",
    "**Student ID: 20709541**\n",
    "\n",
    "_Note:_ Please include your numerical student ID only, do _not_ include your name.\n",
    "\n",
    "_Note:_ Refer to the [PDF](https://github.com/celiasmith/syde556-f22/raw/master/assignments/assignment_01/syde556_assignment_01.pdf) for the full instructions (including some hints), this notebook contains abbreviated instructions only. Cells you need to fill out are marked with a \"writing hand\" symbol. Of course, you can add new cells in between the instructions, but please leave the instructions intact to facilitate marking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and matplotlib -- you shouldn't need any other libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize # For question 2.1b)\n",
    "\n",
    "# Fix the numpy random seed for reproducible results\n",
    "np.random.seed(18945)\n",
    "\n",
    "# Some formating options\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Representation of Scalars\n",
    "\n",
    "## 1.1 Basic encoding and decoding\n",
    "\n",
    "**a) Computing gain and bias.** In general, for a neuron model $a = G[J]$ (and assuming that the inverse $J = G^{-1}[a]$ exists), solve the following system of equations to compute the gain $\\alpha$, and the bias $J^\\mathrm{bias}$ given a maximum rate $a^\\mathrm{max}$ and an $x$-intercept $\\xi$.\n",
    "\n",
    "$$a^\\mathrm{max} = G[\\alpha + J^\\mathrm{bias}] \\,, \\quad\\quad 0 = G[\\alpha \\xi + J^\\mathrm{bias}] \\,.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving the following system of equations we see that:\n",
    "\n",
    "$$\n",
    "\\alpha^\\mathrm{max} = G[\\alpha + J^\\mathrm{bias}] \\Rightarrow G^{-1}[\\alpha^\\mathrm{max}]=a+J^\\mathrm{bias} \\text{ (1)}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "0 = G[\\alpha \\xi + J^\\mathrm{bias}] \\Rightarrow G^{-1}[0]=\\alpha \\xi +J^\\mathrm{bias} \\text{ (2)}\n",
    "$$\n",
    "\n",
    "from (2) it follows that\n",
    "\n",
    "$$\n",
    "J^\\mathrm{bias}=G^{-1}[0]-\\alpha \\xi \\text{ (3)}\n",
    "$$\n",
    "\n",
    "then plugging (3) into (1) we see that\n",
    "\n",
    "$$\n",
    "G^{-1}[a^\\mathrm{max}]=\\alpha+G^{-1}[0]-\\alpha \\xi \\text{ (4)}\n",
    "$$\n",
    "\n",
    "Re-arranging (4) we can find an equation for $\\alpha$ as follows\n",
    "\n",
    "$$\n",
    "\\alpha = \\frac{G^{-1}[a^\\mathrm{max}]-G^{-1}[0]}{1-\\xi} \\text{  (5)}\n",
    "$$\n",
    "\n",
    "and plugging (5) back into (3) we can find the following equation for $J^\\mathrm{bias}$\n",
    "\n",
    "$$\n",
    "J^\\mathrm{bias}=G^{-1}[0]-\\xi \\left\\{\\frac{G^{-1}[a^\\mathrm{max}]-G^{-1}[0]}{1-\\xi}\\right\\} \\text{ (6)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, simplify these equations for the specific case $G[J] = \\max(J, 0)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $G[J] = \\max(J, 0)$, using equations (5) and (6) above we know that $G[J]=J$ so it follows that $G[a^\\mathrm{max}]$ and $G^{-1}[a^\\mathrm{max}]=\\frac{1}{a^\\mathrm{max}}$. Assuming that $G^{-1}[0]=J_{th}$ then\n",
    "\n",
    "$$\n",
    "a=\\frac{\\frac{1}{a^\\mathrm{max}}-J_{th}}{1-\\xi} \\text{ (7)}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "J^\\mathrm{bias}=J_{th}-\\xi \\left\\{\\frac{\\frac{1}{a^\\mathrm{max}}-J_{th}}{1-\\xi} \\right\\} \\text{ (8)}\n",
    "$$\n",
    "\n",
    "We also know that in the case of the ReLU rate approximation encoder, $J^{th}$ being the maximum current that results in a zero output rate corresponds directly with the $x-intercept$ $\\xi$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Neuron tuning curves.** Plot the neuron tuning curves $a_i(x)$ for 16 randomly generated neurons following the intercept and maximum rate distributions described above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_encoders = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random $a^{max}$ uniformely distributed between 100Hz and 200Hz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq = 100\n",
    "high_freq = 200\n",
    "num_a_max_samples = number_of_encoders\n",
    "a_max_set = np.random.uniform(low_freq, high_freq, num_a_max_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random $x-intercepts$ $\\xi$ uniformly distributed between -0.95 and 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_intercept = -0.95\n",
    "max_intercept = 0.95\n",
    "num_intercepts = number_of_encoders\n",
    "intercept_set = np.random.uniform(min_intercept, max_intercept, num_intercepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random signed encoders $e$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_signs=(2*np.random.randint(0,2,size=(number_of_encoders))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a set of 16 random encoders $a_i(x)$ based on an basic encoder class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(a_max, x_intercept):\n",
    "    inv_a_max = 1 / a_max\n",
    "    numerator = inv_a_max - x_intercept\n",
    "    demom = 1 - x_intercept\n",
    "    return numerator / demom\n",
    "\n",
    "\n",
    "def bias(a_max, x_intercept):\n",
    "    gain_term = gain(a_max, x_intercept)\n",
    "    return x_intercept - x_intercept * gain_term\n",
    "\n",
    "\n",
    "def relu_encode(encoder, x):\n",
    "    if encoder.encoder_sign < 0:\n",
    "        if x > encoder.x_intercept:\n",
    "            return 0\n",
    "    if encoder.encoder_sign > 0:\n",
    "        if x < encoder.x_intercept:\n",
    "            return 0\n",
    "    J = encoder.a * x + encoder.j_bias\n",
    "    return J\n",
    "\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, a_max, x_intercept, encoder_sign, id):\n",
    "        self.id = id\n",
    "        self.a_max = a_max\n",
    "        self.x_intercept = x_intercept\n",
    "        self.encoder_sign = encoder_sign\n",
    "        a = gain(a_max, x_intercept)\n",
    "        j_bias = bias(a_max, x_intercept)\n",
    "        self.a = a\n",
    "        self.j_bias = j_bias\n",
    "        self.rate = []\n",
    "\n",
    "    def rate_at_point(self, x):\n",
    "        return relu_encode(self, x)\n",
    "\n",
    "    def find_rate(self, space):\n",
    "        for element in space:\n",
    "            self.rate.append(self.rate_at_point(element))\n",
    "\n",
    "    def print_details(self):\n",
    "        print(\"Encoder: --------------\")\n",
    "        print(\"id \" + str(self.id))\n",
    "        print(\"a_max \" + str(self.a_max))\n",
    "        print(\"intercept \" + str(self.x_intercept))\n",
    "        print(\"gain \" + str(self.a))\n",
    "        print(\"bias \" + str(self.j_bias))\n",
    "        print(\"--------------\")\n",
    "\n",
    "\n",
    "# create array of encoder objects\n",
    "encoders = []\n",
    "for i in range(number_of_encoders):\n",
    "    encoders.append(Encoder(a_max_set[i], intercept_set[i], encoder_signs[i], i))\n",
    "\n",
    "# create a linespace for us to plot\n",
    "space = np.linspace(-1, 1, 41)\n",
    "\n",
    "for encoder in encoders:\n",
    "    encoder.find_rate(space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the ReLU encoder rates $a_i(x)$ over their input $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"384.898437pt\" height=\"262.19625pt\" viewBox=\"0 0 384.898437 262.19625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-09-24T13:37:58.807610</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.6.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 384.898437 262.19625 \nL 384.898437 0 \nL 0 0 \nL 0 262.19625 \nz\n\" style=\"fill: none\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 42.898438 224.64 \nL 377.698438 224.64 \nL 377.698438 7.2 \nL 42.898438 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m289fdbfa86\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m289fdbfa86\" x=\"58.116619\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −1.00 -->\n      <g transform=\"translate(42.793963 239.238437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m289fdbfa86\" x=\"96.162074\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −0.75 -->\n      <g transform=\"translate(80.839418 239.238437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m289fdbfa86\" x=\"134.207528\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −0.50 -->\n      <g transform=\"translate(118.884872 239.238437) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m289fdbfa86\" x=\"172.252983\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- −0.25 -->\n      <g transform=\"translate(156.930327 239.238437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m289fdbfa86\" x=\"210.298438\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.00 -->\n      <g transform=\"translate(199.165625 239.238437) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m289fdbfa86\" x=\"248.343892\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.25 -->\n      <g transform=\"translate(237.21108 239.238437) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m289fdbfa86\" x=\"286.389347\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.50 -->\n      <g transform=\"translate(275.256534 239.238437) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m289fdbfa86\" x=\"324.434801\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.75 -->\n      <g transform=\"translate(313.301989 239.238437) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m289fdbfa86\" x=\"362.480256\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.00 -->\n      <g transform=\"translate(351.347443 239.238437) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- x -->\n     <g transform=\"translate(207.339063 252.916562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \nL 2247 1797 \nL 3578 0 \nL 2900 0 \nL 1881 1375 \nL 863 0 \nL 184 0 \nL 1544 1831 \nL 300 3500 \nL 978 3500 \nL 1906 2253 \nL 2834 3500 \nL 3513 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-78\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m707bd5638d\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m707bd5638d\" x=\"42.898438\" y=\"217.166924\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- −1 -->\n      <g transform=\"translate(21.15625 220.966143) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m707bd5638d\" x=\"42.898438\" y=\"189.486244\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0 -->\n      <g transform=\"translate(29.535937 193.285463) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m707bd5638d\" x=\"42.898438\" y=\"161.805565\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1 -->\n      <g transform=\"translate(29.535937 165.604783) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m707bd5638d\" x=\"42.898438\" y=\"134.124885\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 2 -->\n      <g transform=\"translate(29.535937 137.924104) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m707bd5638d\" x=\"42.898438\" y=\"106.444205\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 3 -->\n      <g transform=\"translate(29.535937 110.243424) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#m707bd5638d\" x=\"42.898438\" y=\"78.763525\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 4 -->\n      <g transform=\"translate(29.535937 82.562744) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m707bd5638d\" x=\"42.898438\" y=\"51.082846\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 5 -->\n      <g transform=\"translate(29.535937 54.882065) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use xlink:href=\"#m707bd5638d\" x=\"42.898438\" y=\"23.402166\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 6 -->\n      <g transform=\"translate(29.535937 27.201385) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- a_i(x) -->\n     <g transform=\"translate(14.798438 129.734062) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-61\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"61.279297\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"111.279297\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"139.0625\"/>\n      <use xlink:href=\"#DejaVuSans-78\" x=\"178.076172\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"237.255859\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 58.116619 189.486244 \nL 65.72571 189.486244 \nL 73.334801 189.486244 \nL 80.943892 189.486244 \nL 88.552983 189.486244 \nL 96.162074 189.486244 \nL 103.771165 189.486244 \nL 111.380256 189.486244 \nL 118.989347 189.486244 \nL 126.598438 189.486244 \nL 134.207528 189.486244 \nL 141.816619 189.486244 \nL 149.42571 189.486244 \nL 157.034801 189.486244 \nL 164.643892 189.486244 \nL 172.252983 189.486244 \nL 179.862074 189.486244 \nL 187.471165 189.486244 \nL 195.080256 189.486244 \nL 202.689347 191.136881 \nL 210.298438 191.049415 \nL 217.907528 190.961949 \nL 225.516619 190.874483 \nL 233.12571 190.787018 \nL 240.734801 190.699552 \nL 248.343892 190.612086 \nL 255.952983 190.52462 \nL 263.562074 190.437155 \nL 271.171165 190.349689 \nL 278.780256 190.262223 \nL 286.389347 190.174758 \nL 293.998438 190.087292 \nL 301.607528 189.999826 \nL 309.216619 189.91236 \nL 316.82571 189.824895 \nL 324.434801 189.737429 \nL 332.043892 189.649963 \nL 339.652983 189.562497 \nL 347.262074 189.475032 \nL 354.871165 189.387566 \nL 362.480256 189.3001 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 58.116619 189.486244 \nL 65.72571 189.486244 \nL 73.334801 189.486244 \nL 80.943892 189.486244 \nL 88.552983 189.486244 \nL 96.162074 189.486244 \nL 103.771165 189.486244 \nL 111.380256 189.486244 \nL 118.989347 189.486244 \nL 126.598438 189.486244 \nL 134.207528 189.486244 \nL 141.816619 189.486244 \nL 149.42571 189.486244 \nL 157.034801 189.486244 \nL 164.643892 189.486244 \nL 172.252983 189.486244 \nL 179.862074 189.486244 \nL 187.471165 189.486244 \nL 195.080256 189.486244 \nL 202.689347 189.486244 \nL 210.298438 190.19102 \nL 217.907528 190.148772 \nL 225.516619 190.106525 \nL 233.12571 190.064278 \nL 240.734801 190.02203 \nL 248.343892 189.979783 \nL 255.952983 189.937536 \nL 263.562074 189.895289 \nL 271.171165 189.853041 \nL 278.780256 189.810794 \nL 286.389347 189.768547 \nL 293.998438 189.7263 \nL 301.607528 189.684052 \nL 309.216619 189.641805 \nL 316.82571 189.599558 \nL 324.434801 189.55731 \nL 332.043892 189.515063 \nL 339.652983 189.472816 \nL 347.262074 189.430569 \nL 354.871165 189.388321 \nL 362.480256 189.346074 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 58.116619 203.844505 \nL 65.72571 203.481357 \nL 73.334801 203.118209 \nL 80.943892 202.755061 \nL 88.552983 202.391913 \nL 96.162074 202.028765 \nL 103.771165 201.665617 \nL 111.380256 201.302469 \nL 118.989347 200.939321 \nL 126.598438 200.576173 \nL 134.207528 200.213025 \nL 141.816619 199.849877 \nL 149.42571 199.486729 \nL 157.034801 199.12358 \nL 164.643892 189.486244 \nL 172.252983 189.486244 \nL 179.862074 189.486244 \nL 187.471165 189.486244 \nL 195.080256 189.486244 \nL 202.689347 189.486244 \nL 210.298438 189.486244 \nL 217.907528 189.486244 \nL 225.516619 189.486244 \nL 233.12571 189.486244 \nL 240.734801 189.486244 \nL 248.343892 189.486244 \nL 255.952983 189.486244 \nL 263.562074 189.486244 \nL 271.171165 189.486244 \nL 278.780256 189.486244 \nL 286.389347 189.486244 \nL 293.998438 189.486244 \nL 301.607528 189.486244 \nL 309.216619 189.486244 \nL 316.82571 189.486244 \nL 324.434801 189.486244 \nL 332.043892 189.486244 \nL 339.652983 189.486244 \nL 347.262074 189.486244 \nL 354.871165 189.486244 \nL 362.480256 189.486244 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 58.116619 129.043488 \nL 65.72571 130.550708 \nL 73.334801 132.057928 \nL 80.943892 133.565148 \nL 88.552983 135.072368 \nL 96.162074 136.579588 \nL 103.771165 138.086808 \nL 111.380256 139.594027 \nL 118.989347 141.101247 \nL 126.598438 142.608467 \nL 134.207528 144.115687 \nL 141.816619 145.622907 \nL 149.42571 147.130127 \nL 157.034801 148.637347 \nL 164.643892 150.144566 \nL 172.252983 151.651786 \nL 179.862074 153.159006 \nL 187.471165 154.666226 \nL 195.080256 156.173446 \nL 202.689347 157.680666 \nL 210.298438 159.187886 \nL 217.907528 160.695106 \nL 225.516619 162.202325 \nL 233.12571 163.709545 \nL 240.734801 165.216765 \nL 248.343892 166.723985 \nL 255.952983 168.231205 \nL 263.562074 169.738425 \nL 271.171165 171.245645 \nL 278.780256 172.752865 \nL 286.389347 174.260084 \nL 293.998438 189.486244 \nL 301.607528 189.486244 \nL 309.216619 189.486244 \nL 316.82571 189.486244 \nL 324.434801 189.486244 \nL 332.043892 189.486244 \nL 339.652983 189.486244 \nL 347.262074 189.486244 \nL 354.871165 189.486244 \nL 362.480256 189.486244 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 58.116619 189.486244 \nL 65.72571 189.486244 \nL 73.334801 189.486244 \nL 80.943892 189.486244 \nL 88.552983 189.486244 \nL 96.162074 189.486244 \nL 103.771165 209.06746 \nL 111.380256 208.487275 \nL 118.989347 207.907089 \nL 126.598438 207.326904 \nL 134.207528 206.746718 \nL 141.816619 206.166533 \nL 149.42571 205.586347 \nL 157.034801 205.006162 \nL 164.643892 204.425976 \nL 172.252983 203.845791 \nL 179.862074 203.265605 \nL 187.471165 202.68542 \nL 195.080256 202.105234 \nL 202.689347 201.525049 \nL 210.298438 200.944863 \nL 217.907528 200.364678 \nL 225.516619 199.784492 \nL 233.12571 199.204307 \nL 240.734801 198.624121 \nL 248.343892 198.043936 \nL 255.952983 197.46375 \nL 263.562074 196.883565 \nL 271.171165 196.303379 \nL 278.780256 195.723194 \nL 286.389347 195.143008 \nL 293.998438 194.562823 \nL 301.607528 193.982637 \nL 309.216619 193.402452 \nL 316.82571 192.822266 \nL 324.434801 192.242081 \nL 332.043892 191.661895 \nL 339.652983 191.08171 \nL 347.262074 190.501524 \nL 354.871165 189.921338 \nL 362.480256 189.341153 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 58.116619 189.486244 \nL 65.72571 189.486244 \nL 73.334801 189.486244 \nL 80.943892 189.486244 \nL 88.552983 189.486244 \nL 96.162074 189.486244 \nL 103.771165 189.486244 \nL 111.380256 189.486244 \nL 118.989347 189.486244 \nL 126.598438 189.486244 \nL 134.207528 189.486244 \nL 141.816619 189.486244 \nL 149.42571 189.486244 \nL 157.034801 189.486244 \nL 164.643892 189.486244 \nL 172.252983 189.486244 \nL 179.862074 189.486244 \nL 187.471165 194.680591 \nL 195.080256 194.445261 \nL 202.689347 194.209931 \nL 210.298438 193.974602 \nL 217.907528 193.739272 \nL 225.516619 193.503943 \nL 233.12571 193.268613 \nL 240.734801 193.033283 \nL 248.343892 192.797954 \nL 255.952983 192.562624 \nL 263.562074 192.327295 \nL 271.171165 192.091965 \nL 278.780256 191.856635 \nL 286.389347 191.621306 \nL 293.998438 191.385976 \nL 301.607528 191.150647 \nL 309.216619 190.915317 \nL 316.82571 190.679987 \nL 324.434801 190.444658 \nL 332.043892 190.209328 \nL 339.652983 189.973998 \nL 347.262074 189.738669 \nL 354.871165 189.503339 \nL 362.480256 189.26801 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 58.116619 189.486244 \nL 65.72571 189.486244 \nL 73.334801 189.486244 \nL 80.943892 189.486244 \nL 88.552983 189.486244 \nL 96.162074 189.486244 \nL 103.771165 189.486244 \nL 111.380256 189.486244 \nL 118.989347 189.486244 \nL 126.598438 189.486244 \nL 134.207528 189.486244 \nL 141.816619 189.486244 \nL 149.42571 189.486244 \nL 157.034801 189.486244 \nL 164.643892 189.486244 \nL 172.252983 189.486244 \nL 179.862074 189.486244 \nL 187.471165 189.486244 \nL 195.080256 189.486244 \nL 202.689347 189.486244 \nL 210.298438 189.486244 \nL 217.907528 189.486244 \nL 225.516619 189.486244 \nL 233.12571 189.486244 \nL 240.734801 189.486244 \nL 248.343892 189.486244 \nL 255.952983 189.486244 \nL 263.562074 189.486244 \nL 271.171165 189.486244 \nL 278.780256 177.675689 \nL 286.389347 178.736624 \nL 293.998438 179.79756 \nL 301.607528 180.858495 \nL 309.216619 181.91943 \nL 316.82571 182.980366 \nL 324.434801 184.041301 \nL 332.043892 185.102237 \nL 339.652983 186.163172 \nL 347.262074 187.224108 \nL 354.871165 188.285043 \nL 362.480256 189.345979 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #e377c2; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 58.116619 189.486244 \nL 65.72571 189.486244 \nL 73.334801 214.756364 \nL 80.943892 214.086252 \nL 88.552983 213.416141 \nL 96.162074 212.746029 \nL 103.771165 212.075918 \nL 111.380256 211.405807 \nL 118.989347 210.735695 \nL 126.598438 210.065584 \nL 134.207528 209.395472 \nL 141.816619 208.725361 \nL 149.42571 208.05525 \nL 157.034801 207.385138 \nL 164.643892 206.715027 \nL 172.252983 206.044915 \nL 179.862074 205.374804 \nL 187.471165 204.704693 \nL 195.080256 204.034581 \nL 202.689347 203.36447 \nL 210.298438 202.694359 \nL 217.907528 202.024247 \nL 225.516619 201.354136 \nL 233.12571 200.684024 \nL 240.734801 200.013913 \nL 248.343892 199.343802 \nL 255.952983 198.67369 \nL 263.562074 198.003579 \nL 271.171165 197.333467 \nL 278.780256 196.663356 \nL 286.389347 195.993245 \nL 293.998438 195.323133 \nL 301.607528 194.653022 \nL 309.216619 193.98291 \nL 316.82571 193.312799 \nL 324.434801 192.642688 \nL 332.043892 191.972576 \nL 339.652983 191.302465 \nL 347.262074 190.632353 \nL 354.871165 189.962242 \nL 362.480256 189.292131 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #7f7f7f; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 58.116619 106.936839 \nL 65.72571 108.995587 \nL 73.334801 111.054334 \nL 80.943892 113.113082 \nL 88.552983 115.17183 \nL 96.162074 117.230578 \nL 103.771165 119.289325 \nL 111.380256 121.348073 \nL 118.989347 123.406821 \nL 126.598438 125.465569 \nL 134.207528 127.524316 \nL 141.816619 129.583064 \nL 149.42571 131.641812 \nL 157.034801 133.70056 \nL 164.643892 135.759307 \nL 172.252983 137.818055 \nL 179.862074 139.876803 \nL 187.471165 141.935551 \nL 195.080256 143.994298 \nL 202.689347 146.053046 \nL 210.298438 148.111794 \nL 217.907528 150.170542 \nL 225.516619 152.229289 \nL 233.12571 154.288037 \nL 240.734801 156.346785 \nL 248.343892 158.405533 \nL 255.952983 160.46428 \nL 263.562074 162.523028 \nL 271.171165 164.581776 \nL 278.780256 166.640524 \nL 286.389347 168.699271 \nL 293.998438 170.758019 \nL 301.607528 172.816767 \nL 309.216619 189.486244 \nL 316.82571 189.486244 \nL 324.434801 189.486244 \nL 332.043892 189.486244 \nL 339.652983 189.486244 \nL 347.262074 189.486244 \nL 354.871165 189.486244 \nL 362.480256 189.486244 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #bcbd22; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 58.116619 17.083636 \nL 65.72571 21.389701 \nL 73.334801 25.695765 \nL 80.943892 30.00183 \nL 88.552983 34.307895 \nL 96.162074 38.613959 \nL 103.771165 42.920024 \nL 111.380256 47.226088 \nL 118.989347 51.532153 \nL 126.598438 55.838217 \nL 134.207528 60.144282 \nL 141.816619 64.450346 \nL 149.42571 68.756411 \nL 157.034801 73.062475 \nL 164.643892 77.36854 \nL 172.252983 81.674605 \nL 179.862074 85.980669 \nL 187.471165 90.286734 \nL 195.080256 94.592798 \nL 202.689347 98.898863 \nL 210.298438 103.204927 \nL 217.907528 107.510992 \nL 225.516619 111.817056 \nL 233.12571 116.123121 \nL 240.734801 120.429186 \nL 248.343892 124.73525 \nL 255.952983 129.041315 \nL 263.562074 133.347379 \nL 271.171165 137.653444 \nL 278.780256 141.959508 \nL 286.389347 146.265573 \nL 293.998438 150.571637 \nL 301.607528 154.877702 \nL 309.216619 159.183766 \nL 316.82571 163.489831 \nL 324.434801 167.795896 \nL 332.043892 189.486244 \nL 339.652983 189.486244 \nL 347.262074 189.486244 \nL 354.871165 189.486244 \nL 362.480256 189.486244 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #17becf; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 58.116619 160.877616 \nL 65.72571 161.58843 \nL 73.334801 162.299244 \nL 80.943892 163.010059 \nL 88.552983 163.720873 \nL 96.162074 164.431687 \nL 103.771165 165.142502 \nL 111.380256 165.853316 \nL 118.989347 166.56413 \nL 126.598438 167.274945 \nL 134.207528 167.985759 \nL 141.816619 168.696574 \nL 149.42571 169.407388 \nL 157.034801 170.118202 \nL 164.643892 170.829017 \nL 172.252983 171.539831 \nL 179.862074 172.250645 \nL 187.471165 172.96146 \nL 195.080256 173.672274 \nL 202.689347 174.383088 \nL 210.298438 175.093903 \nL 217.907528 175.804717 \nL 225.516619 176.515531 \nL 233.12571 177.226346 \nL 240.734801 177.93716 \nL 248.343892 178.647974 \nL 255.952983 179.358789 \nL 263.562074 189.486244 \nL 271.171165 189.486244 \nL 278.780256 189.486244 \nL 286.389347 189.486244 \nL 293.998438 189.486244 \nL 301.607528 189.486244 \nL 309.216619 189.486244 \nL 316.82571 189.486244 \nL 324.434801 189.486244 \nL 332.043892 189.486244 \nL 339.652983 189.486244 \nL 347.262074 189.486244 \nL 354.871165 189.486244 \nL 362.480256 189.486244 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 58.116619 159.591795 \nL 65.72571 160.335241 \nL 73.334801 161.078688 \nL 80.943892 161.822134 \nL 88.552983 162.565581 \nL 96.162074 163.309027 \nL 103.771165 164.052473 \nL 111.380256 164.79592 \nL 118.989347 165.539366 \nL 126.598438 166.282813 \nL 134.207528 167.026259 \nL 141.816619 167.769705 \nL 149.42571 168.513152 \nL 157.034801 169.256598 \nL 164.643892 170.000045 \nL 172.252983 170.743491 \nL 179.862074 171.486937 \nL 187.471165 172.230384 \nL 195.080256 172.97383 \nL 202.689347 173.717277 \nL 210.298438 174.460723 \nL 217.907528 175.20417 \nL 225.516619 175.947616 \nL 233.12571 176.691062 \nL 240.734801 177.434509 \nL 248.343892 178.177955 \nL 255.952983 178.921402 \nL 263.562074 179.664848 \nL 271.171165 189.486244 \nL 278.780256 189.486244 \nL 286.389347 189.486244 \nL 293.998438 189.486244 \nL 301.607528 189.486244 \nL 309.216619 189.486244 \nL 316.82571 189.486244 \nL 324.434801 189.486244 \nL 332.043892 189.486244 \nL 339.652983 189.486244 \nL 347.262074 189.486244 \nL 354.871165 189.486244 \nL 362.480256 189.486244 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 58.116619 189.486244 \nL 65.72571 189.486244 \nL 73.334801 189.486244 \nL 80.943892 189.486244 \nL 88.552983 189.486244 \nL 96.162074 189.486244 \nL 103.771165 189.486244 \nL 111.380256 189.486244 \nL 118.989347 189.486244 \nL 126.598438 189.486244 \nL 134.207528 189.486244 \nL 141.816619 189.486244 \nL 149.42571 189.486244 \nL 157.034801 189.486244 \nL 164.643892 189.486244 \nL 172.252983 197.100283 \nL 179.862074 196.788046 \nL 187.471165 196.475809 \nL 195.080256 196.163573 \nL 202.689347 195.851336 \nL 210.298438 195.539099 \nL 217.907528 195.226863 \nL 225.516619 194.914626 \nL 233.12571 194.602389 \nL 240.734801 194.290153 \nL 248.343892 193.977916 \nL 255.952983 193.665679 \nL 263.562074 193.353443 \nL 271.171165 193.041206 \nL 278.780256 192.728969 \nL 286.389347 192.416733 \nL 293.998438 192.104496 \nL 301.607528 191.792259 \nL 309.216619 191.480023 \nL 316.82571 191.167786 \nL 324.434801 190.855549 \nL 332.043892 190.543313 \nL 339.652983 190.231076 \nL 347.262074 189.918839 \nL 354.871165 189.606603 \nL 362.480256 189.294366 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 58.116619 189.486244 \nL 65.72571 189.486244 \nL 73.334801 189.486244 \nL 80.943892 189.486244 \nL 88.552983 189.486244 \nL 96.162074 189.486244 \nL 103.771165 189.486244 \nL 111.380256 189.486244 \nL 118.989347 189.486244 \nL 126.598438 189.486244 \nL 134.207528 189.486244 \nL 141.816619 189.486244 \nL 149.42571 189.486244 \nL 157.034801 189.486244 \nL 164.643892 189.486244 \nL 172.252983 189.486244 \nL 179.862074 189.486244 \nL 187.471165 189.486244 \nL 195.080256 189.486244 \nL 202.689347 189.486244 \nL 210.298438 189.486244 \nL 217.907528 189.486244 \nL 225.516619 189.486244 \nL 233.12571 189.486244 \nL 240.734801 189.486244 \nL 248.343892 189.486244 \nL 255.952983 189.486244 \nL 263.562074 189.486244 \nL 271.171165 189.486244 \nL 278.780256 178.38984 \nL 286.389347 179.385672 \nL 293.998438 180.381504 \nL 301.607528 181.377337 \nL 309.216619 182.373169 \nL 316.82571 183.369001 \nL 324.434801 184.364833 \nL 332.043892 185.360665 \nL 339.652983 186.356497 \nL 347.262074 187.352329 \nL 354.871165 188.348162 \nL 362.480256 189.343994 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 58.116619 189.486244 \nL 65.72571 189.486244 \nL 73.334801 189.486244 \nL 80.943892 189.486244 \nL 88.552983 189.486244 \nL 96.162074 189.486244 \nL 103.771165 189.486244 \nL 111.380256 189.486244 \nL 118.989347 189.486244 \nL 126.598438 189.486244 \nL 134.207528 189.486244 \nL 141.816619 189.486244 \nL 149.42571 189.486244 \nL 157.034801 189.486244 \nL 164.643892 189.486244 \nL 172.252983 189.486244 \nL 179.862074 189.486244 \nL 187.471165 189.486244 \nL 195.080256 189.486244 \nL 202.689347 191.752752 \nL 210.298438 191.636616 \nL 217.907528 191.520479 \nL 225.516619 191.404343 \nL 233.12571 191.288207 \nL 240.734801 191.17207 \nL 248.343892 191.055934 \nL 255.952983 190.939797 \nL 263.562074 190.823661 \nL 271.171165 190.707524 \nL 278.780256 190.591388 \nL 286.389347 190.475251 \nL 293.998438 190.359115 \nL 301.607528 190.242979 \nL 309.216619 190.126842 \nL 316.82571 190.010706 \nL 324.434801 189.894569 \nL 332.043892 189.778433 \nL 339.652983 189.662296 \nL 347.262074 189.54616 \nL 354.871165 189.430024 \nL 362.480256 189.313887 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 58.116619 202.687934 \nL 65.72571 202.352497 \nL 73.334801 202.017061 \nL 80.943892 201.681624 \nL 88.552983 201.346188 \nL 96.162074 201.010752 \nL 103.771165 200.675315 \nL 111.380256 200.339879 \nL 118.989347 200.004442 \nL 126.598438 199.669006 \nL 134.207528 199.333569 \nL 141.816619 198.998133 \nL 149.42571 198.662697 \nL 157.034801 198.32726 \nL 164.643892 189.486244 \nL 172.252983 189.486244 \nL 179.862074 189.486244 \nL 187.471165 189.486244 \nL 195.080256 189.486244 \nL 202.689347 189.486244 \nL 210.298438 189.486244 \nL 217.907528 189.486244 \nL 225.516619 189.486244 \nL 233.12571 189.486244 \nL 240.734801 189.486244 \nL 248.343892 189.486244 \nL 255.952983 189.486244 \nL 263.562074 189.486244 \nL 271.171165 189.486244 \nL 278.780256 189.486244 \nL 286.389347 189.486244 \nL 293.998438 189.486244 \nL 301.607528 189.486244 \nL 309.216619 189.486244 \nL 316.82571 189.486244 \nL 324.434801 189.486244 \nL 332.043892 189.486244 \nL 339.652983 189.486244 \nL 347.262074 189.486244 \nL 354.871165 189.486244 \nL 362.480256 189.486244 \n\" clip-path=\"url(#p881fff6c78)\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 42.898438 224.64 \nL 42.898438 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 377.698438 224.64 \nL 377.698438 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 42.898438 224.64 \nL 377.698438 224.64 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 42.898438 7.2 \nL 377.698438 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p881fff6c78\">\n   <rect x=\"42.898438\" y=\"7.2\" width=\"334.8\" height=\"217.44\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for encoder in encoders:\n",
    "    plt.plot(space, encoder.rate)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('a(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Computing identity decoders.** Compute the optimal identity decoder $\\vec d$ for those 16 neurons (as shown in class). Report the value of the individual decoder coefficients. Compute $d$ using the matrix notation mentioned in the course notes. Do not apply any regularization. $A$ is the matrix of activities (the same data used to generate the plot in 1.1b).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Evaluating decoding errors.** Compute and plot $\\hat{x}=\\sum_i d_i a_i(x)$. Overlay on the plot the line $y=x$. Make a separate plot of $x-\\hat{x}$ to see what the error looks like. Report the Root Mean Squared Error (RMSE) value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Decoding under noise.** Now try decoding under noise. Add random normally distributed noise to $a$ and decode again. The noise is a random variable with mean $\\mu=0$ and standard deviation of $\\sigma=0.2 \\max(A)$ (where $\\max(A)$ is the maximum firing rate of all the neurons). Resample this variable for every different $x$ value for every different neuron. Create all the same plots as in part d). Report the RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Accounting for decoder noise.** Recompute the decoder $\\vec d$ taking noise into account (i.e., apply the appropriate regularization, as shown in class). Show how these decoders behave when decoding both with and without noise added to $a$ by making the same plots as in d) and e). Report the RMSE for all cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g) Interpretation.** Show a 2x2 table of the four RMSE values reported in parts d), e), and f). This should show the effects of adding noise and whether the decoders $d$ are computed taking noise into account. Write a few sentences commenting on what the table shows, i.e., what the effect of adding noise to the activities is with respect to the measured error and why accounting for noise when computing the decoders increases/decreases/does not change the measured RMSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ \\<YOUR SOLUTION HERE\\>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Exploring sources of error\n",
    "\n",
    "**a) Exploring error due to distortion and noise.** Plot the error due to distortion $E_\\mathrm{dist}$ and the error due to noise $E_\\mathrm{noise}$ as a function of $n$, the number of neurons. Generate two different loglog plots (one for each type of error) with $n$ values of at least $[4, 8, 16, 32, 64, 128, 256, 512]$. For each $n$ value, do at least $5$ runs and average the results. For each run, different $\\alpha$, $J^\\mathrm{bias}$, and $e$ values should be generated for each neuron. Compute $d$ taking noise into account, with $\\sigma = 0.1 \\max(A)$. Show visually that the errors are proportional to $1/n$ or $1/n^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Adapting the noise level.** Repeat part a) with $\\sigma = 0.01 \\max(A)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Interpretation.** What does the difference between the graphs in a) and b) tell us about the sources of error in neural populations?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ \\<YOUR SOLUTION HERE\\>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Leaky Integrate-and-Fire neurons\n",
    "\n",
    "**a) Computing gain and bias.** As in the second part of 1.1a), given a maximum firing rate $a^\\mathrm{max}$ and a bias $J^\\mathrm{bias}$, write down the equations for computing $\\alpha$ and the $J^\\mathrm{bias}$ for this specific neuron model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ \\<YOUR SOLUTION HERE\\>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Neuron tuning curves.** Generate the same plot as in 1.1b). Use $\\tau_\\mathrm{ref}=2 \\mathrm{ms}$ and $\\tau_{RC}=20 \\mathrm{ms}$. Use the same distribution of $x$-intercepts and maximum firing rates as in 1.1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Impact of noise.** Generate the same four plots as in 1.1f) (adding/not adding noise to $A$, accounting/not accounting for noise when computing $\\vec d$), and report the RMSE both with and without noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reperesentation of Vectors\n",
    "\n",
    "## 2.1 Vector tuning curves\n",
    "\n",
    "**a) Plotting 2D tuning curves.** Plot the tuning curve of an LIF neuron whose 2D preferred direction vector is at an angle of $\\theta=-\\pi/4$, has an $x$-intercept at the origin $(0,0)$, and has a maximum firing rate of $100 \\mathrm{Hz}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Plotting the 2D tuning curve along the unit circle.** Plot the tuning curve for the same neuron as in a), but only considering the points around the unit circle, i.e., sample the activation for different angles $\\theta$. Fit a curve of the form $c_1 \\cos(c_2\\theta+c_3)+c_4$ to the tuning curve and plot it as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Discussion.** What makes a cosine a good choice for the curve fit in 2.1b? Why does it differ from the ideal curve?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ \\<YOUR SOLUTION HERE\\>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Vector representation\n",
    "\n",
    "**a) Choosing encoding vectors.** Generate a set of $100$ random unit vectors uniformly distributed around the unit circle. These will be the encoders $\\vec e$ for $100$ neurons. Plot these vectors with a quiver or line plot (i.e., not just points, but lines/arrows to the points).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Computing the identity decoder.** Use LIF neurons with the same properties as in question 1.3. When computing the decoders, take into account noise with $\\sigma = 0.2\\max(A)$. Plot the decoders in the same way you plotted the encoders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Discussion.** How do these decoding vectors compare to the encoding vectors?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ \\<YOUR SOLUTION HERE\\>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Testing the decoder.** Generate 20 random $\\vec x$ values throughout the unit circle (i.e.,~with different directions and radiuses). For each $\\vec x$ value, determine the neural activity $a_i$ for each of the 100 neurons. Now decode these values (i.e. compute $\\hat{x} = D \\vec a$) using the decoders from part b). Plot the original and decoded values on the same graph in different colours, and compute the RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Using encoders as decoders.** Repeat part d) but use the _encoders_ as decoders. This is what Georgopoulos used in his original approach to decoding information from populations of neurons. Plot the decoded values and compute the RMSE. In addition, recompute the RMSE in both cases, but ignore the magnitude of the decoded vectors by normalizing before computing the RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ <YOUR SOLUTION HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Discussion.** When computing the RMSE on the normalized vectors, using the encoders as decoders should result in a larger, yet still surprisingly small error. Thinking about random unit vectors in high dimensional spaces, why is this the case? What are the relative merits of these two approaches to decoding?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ \\<YOUR SOLUTION HERE\\>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
